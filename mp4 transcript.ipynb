{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1b1bb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: empowerment is Authority it is a signed permission slip to actually seize the day it's the process of getting stronger and more confident and more engaged and to be empowered is to move through the world without any kind of fear or any kind of apology and with these gifts comes and even deeper privilege I believe and that is the ability to take charge of your own life to own yourself and clean your right and here's what I know for sure that to how much is given much is expected and I have been given so much I've earned it I've been blessed with it but I've been giving a lot and that's why I've chosen to use my life to lift other people up if things go wrong you hit a dead end as you will it's just life's way of saying time to change course so ask every failure this is what I do every failure every crisis every time I say what is this here to teach me and as soon as you get the lesson you get to move on if you really get the message to give you some remedial work\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "audio = False\n",
    "\n",
    "with sr.AudioFile(\"oprah.wav\") as source:\n",
    "    audio = r.record(source)\n",
    "try:\n",
    "    s = r.recognize_google(audio)\n",
    "    print(\"Text: \"+s)\n",
    "except Exception as e:\n",
    "    print(\"Exception: \"+str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46cd389d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.]])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Function to detect silent regions in audio array\n",
    "def detect_silence(audio_array, threshold=0, min_silence_duration=100):\n",
    "    silent_regions = []\n",
    "    start_idx = None\n",
    "    for idx, sample in enumerate(audio_array):\n",
    "        if abs(sample).all() < threshold:\n",
    "            if start_idx is None:\n",
    "                start_idx = idx\n",
    "        elif start_idx is not None:\n",
    "            duration = idx - start_idx\n",
    "            if duration >= min_silence_duration:\n",
    "                silent_regions.append((start_idx, idx))\n",
    "            start_idx = None\n",
    "    if start_idx is not None:\n",
    "        silent_regions.append((start_idx, len(audio_array)))\n",
    "    return silent_regions\n",
    "\n",
    "# Function to split audio array at silent regions\n",
    "def split_audio_at_silence(audio_array, silent_regions):\n",
    "    audio_chunks = []\n",
    "    for start, end in silent_regions:\n",
    "        audio_chunks.append(audio_array[start:end])\n",
    "    return audio_chunks\n",
    "\n",
    "# Load the WAV audio file\n",
    "audio_array, sample_rate = sf.read(\"watts_cropped.wav\")\n",
    "\n",
    "# Detect silent regions in the audio\n",
    "silent_regions = detect_silence(audio_array, threshold=1, min_silence_duration=2)\n",
    "\n",
    "# Split the audio at silent regions\n",
    "audio_chunks = split_audio_at_silence(audio_array, silent_regions)\n",
    "audio_chunks\n",
    "\n",
    "# # Optionally, save each chunk as a separate WAV file\n",
    "# for i, chunk in enumerate(audio_chunks):\n",
    "#     sf.write(f\"chunk_{i}.wav\", chunk, sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1245be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting chunk0.wav.\n",
      "Exporting chunk1.wav.\n",
      "Exporting chunk2.wav.\n",
      "Exporting chunk3.wav.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "if len(sys.argv) < 2:\n",
    "    print(\"No WAV file in input.\")\n",
    "    exit(0)\n",
    "\n",
    "# Load your audio.\n",
    "song = AudioSegment.from_wav('watts_cropped.wav')\n",
    "\n",
    "# the imported function.\n",
    "chunks = split_on_silence (\n",
    "    # Use the loaded audio.\n",
    "    song, \n",
    "    # Specify that a silent chunk must be at least 2 seconds or 2000 ms long.\n",
    "    min_silence_len=2000,\n",
    "    # Consider a chunk silent if it's quieter than -16 dBFS.\n",
    "    # (You may want to adjust this parameter.)\n",
    "    silence_thresh=-40\n",
    ")\n",
    "\n",
    "# Process each chunk with your parameters\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Create a silence chunk that's 0.5 seconds (or 500 ms) long for padding.\n",
    "    silence_chunk = AudioSegment.silent(duration=500)\n",
    "\n",
    "    # Add the padding chunk to the beginning and end of the entire chunk.\n",
    "    audio_chunk = silence_chunk + chunk + silence_chunk\n",
    "\n",
    "    # Export the audio chunk with new bitrate.\n",
    "    print(\"Exporting chunk{0}.wav.\".format(i))\n",
    "    audio_chunk.export(\n",
    "        \"./chunk{0}.wav\".format(i),\n",
    "        format=\"wav\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f11eb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 Text: let's suppose that you were able every night to dream Any Dream you wanted to\n",
      "Chunk 2 Text: 75 years of time or any length of time you wanted to have\n",
      "Chunk 3 Text: and you would naturally as you began on this adventure of dreams you would fulfill all your\n",
      "Chunk 4 Text: 75 years of total pleasure each you would say wow that was pretty great\n"
     ]
    }
   ],
   "source": [
    "# Process each chunk with speech recognition\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Export the chunk to a temporary WAV file\n",
    "    chunk.export(\"temp.wav\", format=\"wav\")\n",
    "    \n",
    "    # Load the temporary WAV file\n",
    "    with sr.AudioFile(\"temp.wav\") as source:\n",
    "        # Record the audio data from the file\n",
    "        audio_data = recognizer.record(source)\n",
    "    \n",
    "    # Perform speech recognition\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(f\"Chunk {i+1} Text:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(f\"Chunk {i+1}: Google Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Chunk {i+1}: Could not request results from Google Speech Recognition service; {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e11dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcript",
   "language": "python",
   "name": "transcript"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
